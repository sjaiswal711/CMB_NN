{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7557a77-cd64-4579-b1bb-363a4e84b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43ad5dc-8a4c-4aa9-9eb9-1a4a43819e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10, 8, 128)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(4, 10, 8, 128)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ec47b4-a7f4-4ee7-a521-85b0388007fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 20, 16, 32)\n"
     ]
    }
   ],
   "source": [
    "y = Conv2DTranspose(32, 2, 2, activation='relu')(x)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5039eae5-140f-471b-8036-8323b609af78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1, 2, 2, 1)\n",
      "Output shape: (1, 4, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "\n",
    "# Example input tensor with shape (batch_size, height, width, channels)\n",
    "input_tensor = tf.random.normal((1, 2, 2, 1))*100  # 1 sample, 2x2 feature map, 1 channel\n",
    "\n",
    "# Apply Transpose Convolution\n",
    "transpose_conv = Conv2DTranspose(filters=1, kernel_size=(2, 2), strides=2, padding=\"same\")\n",
    "output_tensor = transpose_conv(input_tensor)\n",
    "\n",
    "# Show the input and output shapes\n",
    "print(\"Input shape:\", input_tensor.shape)    # (1, 2, 2, 1)\n",
    "print(\"Output shape:\", output_tensor.shape)  # (1, 4, 4, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "779e8fa5-0cf2-4910-a7d6-c54ca70eb50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
       "array([[[[ -0.73362434],\n",
       "         [-31.74546   ]],\n",
       "\n",
       "        [[ 57.681446  ],\n",
       "         [-59.314667  ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeae9750-f9b5-4ef4-a4f8-8e23c5342885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Output after Transpose Convolution:\n",
      "[[1. 0. 2. 0.]\n",
      " [0. 1. 0. 2.]\n",
      " [3. 0. 4. 0.]\n",
      " [0. 3. 0. 4.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input matrix (reshaped to fit Keras requirements for 4D tensors)\n",
    "input_data = np.array([[1, 2], [3, 4]]).reshape((1, 2, 2, 1))  # shape (batch_size, height, width, channels)\n",
    "\n",
    "# Number of filters for Conv2DTranspose (since your kernel is 2x2, we assume 1 filter)\n",
    "num_filters = 1\n",
    "\n",
    "# Create a Keras input layer\n",
    "input_layer = Input(shape=(2, 2, 1))\n",
    "\n",
    "# Define the Conv2DTranspose layer\n",
    "transpose_conv = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\", use_bias=False)(input_layer)\n",
    "\n",
    "# Create a Keras model\n",
    "model = Model(inputs=input_layer, outputs=transpose_conv)\n",
    "\n",
    "# Assign weights manually to replicate your kernel\n",
    "kernel = np.array([[1, 0], [0, 1]]).reshape((2, 2, 1, 1))  # shape (height, width, input_channels, output_channels)\n",
    "model.layers[1].set_weights([kernel])\n",
    "\n",
    "# Apply the model to the input data\n",
    "output = model.predict(input_data)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output after Transpose Convolution:\")\n",
    "print(output[0, :, :, 0])  # Remove batch and channel dimensions for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa51631d-e880-40de-8d18-7d4c3c86fdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e377a96f2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[[[[1]\n",
      "   [2]]\n",
      "\n",
      "  [[3]\n",
      "   [4]]]]\n",
      "Output after Concatenation:\n",
      "[[[[1. 1.]\n",
      "   [2. 0.]]\n",
      "\n",
      "  [[3. 0.]\n",
      "   [4. 1.]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uma/.local/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_11', 'keras_tensor_12']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input tensors (reshaped to fit Keras requirements for 4D tensors)\n",
    "x = np.array([[1, 2], [3, 4]]).reshape((1, 2, 2, 1))  # shape (batch_size, height, width, channels)\n",
    "skip_features = np.array([[1, 0], [0, 1]]).reshape((1, 2, 2, 1))  # shape (batch_size, height, width, channels)\n",
    "\n",
    "# Create Keras Input layers\n",
    "input_x = Input(shape=(2, 2, 1))         # shape for x\n",
    "input_skip = Input(shape=(2, 2, 1))      # shape for skip_features\n",
    "\n",
    "# Concatenate along the channel axis (axis=3)\n",
    "concatenated = Concatenate(axis=-1)([input_x, input_skip])  # axis=-1 means last dimension\n",
    "\n",
    "# Create a Keras model\n",
    "model = Model(inputs=[input_x, input_skip], outputs=concatenated)\n",
    "\n",
    "# Apply the model to the input data\n",
    "output = model.predict([x, skip_features])\n",
    "\n",
    "# Print the output\n",
    "print(x)\n",
    "print(\"Output after Concatenation:\")\n",
    "print(output)  # Remove batch dimension for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61c7a587-5d18-41a6-ab5a-14194d19b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 28, 28, 1), dtype=float32, sparse=False, name=keras_tensor_22>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21632</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">216,330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21632\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │       \u001b[38;5;34m216,330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,650</span> (846.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m216,650\u001b[0m (846.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,650</span> (846.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m216,650\u001b[0m (846.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input shape (28x28 grayscale images)\n",
    "input_shape = (28, 28, 1)  # Height, Width, Channels\n",
    "inputs = Input(shape=input_shape)\n",
    "print(inputs)\n",
    "# Adding layers to the model\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)  # Convolutional layer\n",
    "x = Flatten()(x)  # Flatten the output to feed into a Dense layer\n",
    "x = Dense(10, activation='softmax')(x)  # Fully connected layer for classification\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec7208-ed04-41e8-9d26-dfd07ee02722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
