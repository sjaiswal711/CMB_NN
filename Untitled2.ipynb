{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e4962-3f05-4a79-996d-a85c2d3a212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import healpy as hp\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38a8f5-c0ed-473e-86c3-3be2a28f5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = 7.5 * np.pi / 180\n",
    "theta2 = 85 * np.pi / 180\n",
    "w1 = 2 * np.pi  # rad/min\n",
    "w2 = 2 * w1  # rad/min\n",
    "w3 = 0.000011954  # rad/min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe67759e-cabf-4cfe-9612-1c91d0dc60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_vectors(t):\n",
    "    cos_w1t = np.cos(w1 * t)\n",
    "    sin_w1t = np.sin(w1 * t)\n",
    "\n",
    "    cos_w2t = np.cos(w2 * t)\n",
    "    sin_w2t = np.sin(w2 * t)\n",
    "\n",
    "    cos_theta1 = np.cos(theta1)\n",
    "    sin_theta1 = np.sin(theta1)\n",
    "\n",
    "    cos_theta2 = np.cos(theta2)\n",
    "    sin_theta2 = np.sin(theta2)\n",
    "\n",
    "    A = np.array([[cos_w1t, sin_w1t, 0],\n",
    "                  [-sin_w1t, cos_w1t, 0],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    B = np.array([[1, 0, 0],\n",
    "                  [0, cos_w2t, sin_w2t],\n",
    "                  [0, -sin_w2t, cos_w2t]])\n",
    "\n",
    "    C = np.array([[cos_theta1, 0, sin_theta1],\n",
    "                  [0, 1, 0],\n",
    "                  [-sin_theta1, 0, cos_theta1]])\n",
    "\n",
    "    # time_periods = [1, 2, 3,\n",
    "    D_R = np.array([[cos_theta2],\n",
    "                    [sin_theta2 * np.cos(w3 * t)],\n",
    "                    [sin_theta2 * np.sin(w3 * t)]])\n",
    "\n",
    "    D_S = np.array([[1],\n",
    "                    [0],\n",
    "                    [0]])\n",
    "\n",
    "    result1 = np.dot(np.dot(A, B), C)\n",
    "    result_R = np.matmul(result1, D_R)\n",
    "    result_S = np.matmul(result1, D_S)\n",
    "\n",
    "    return result_R.T.flatten(), result_S.T.flatten()  # Return both flattened vectors\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35305a15-ed59-40ef-a60a-5b6726fef0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Angle between two vector\n",
    "\n",
    "def angle_vec(A, B):\n",
    "    dot_product = np.dot(A, B) \n",
    "    mag_A = np.linalg.norm(A)\n",
    "    mag_B = np.linalg.norm(B)\n",
    "    if (mag_A * mag_B) == 0:\n",
    "        return 0 # To handle the case where one the vector becomes Zeros(R_i == Rc)\n",
    "    cos_theta = dot_product / (mag_A * mag_B)\n",
    "    angle = np.arccos(cos_theta)\n",
    "    return angle\n",
    "\n",
    "def anglev(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    clipped_dp = np.clip(dot_product, -1.0, 1.0) # Clip dot_product to the valid range for arccos to avoid NaNs\n",
    "    angle = np.arccos(clipped_dp)\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7af912-787d-40e1-83af-511f6fe3b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside=16\n",
    "npix = 12*nside**2\n",
    "\n",
    "# time_step=scan_time\n",
    "scan_time = np.sqrt(4*np.pi/npix)/w1\n",
    "\n",
    "# temperature_map = hp.read_map(\"input_map.fits\") \n",
    "\n",
    "# Load the grid\n",
    "grid = np.loadtxt(\"grid.txt\")\n",
    "# grid_size = 2 (in arcsec)convert grid_size in radian\n",
    "grid_size = 2*math.pi / (180 * 3600)\n",
    "centre = (3001,3001)\n",
    "Radius = (50 / 60) * (math.pi / 180) #50 in arcmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a89dd-3edb-4788-b3d4-fe1d99d7ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_time_step(time_step):\n",
    "    \n",
    "    t = time_step  \n",
    "\n",
    "    # 1. Calculate R(t) and S(t) vectors\n",
    "    R, S =  get_vectors(t)\n",
    "\n",
    "    # 2. Calculate pixel number along R(t) vector (ring format)\n",
    "    pix_ring = hp.vec2pix(nside, R[0], R[1], R[2], nest=False)\n",
    "\n",
    "\n",
    "    #3. Calculate Z, I and N (N = I for phi = 0)\n",
    "    Z_t = np.cross(R,S)\n",
    "    I_t = np.cross(R, Z_t)\n",
    "    N_t = I_t\n",
    "    \n",
    "    # 4. Find neighboring pixels in RING format\n",
    "    Rc = hp.pix2vec(nside,pix_ring,nest=False)\n",
    "    neighbours = hp.query_disc(nside, Rc , radius=Radius)\n",
    "\n",
    "    # 5. angular separation between central pixel and neighbouring pixels\n",
    "    x = np.zeros_like(neighbours, dtype=float)\n",
    "    y = np.zeros(len(neighbours))\n",
    "    weight = np.zeros(len(neighbours))\n",
    "    # print(len(neighbours))\n",
    "    for i, neighbour_pix in enumerate(neighbours):\n",
    "        \n",
    "        R_i = hp.pix2vec(nside,neighbour_pix,nest=False)\n",
    "        theta_i = anglev(Rc, R_i)\n",
    "\n",
    "        # 6. A_i = line joining central pixel and neighbour pixel\n",
    "        R_i = hp.pix2vec(nside,neighbour_pix,nest=False)\n",
    "        A_i = np.array(Rc)-np.array(R_i)\n",
    "        # print(\"A_i = \",A_i,\"\\nN_t = \",N_t)\n",
    "        \n",
    "        # 7. angle between N & A_i\n",
    "        alpha_i = angle_vec(A_i, N_t) \n",
    "        # print(\"alpha_i=\",(alpha_i))\n",
    "        # 8. x_i and y_i\n",
    "        x[i] = theta_i * np.cos(alpha_i)\n",
    "        y[i] = theta_i * np.sin(alpha_i)\n",
    "        index_x = int(centre[0] + round(x[i]/grid_size,0))\n",
    "        index_y = int(centre[1] + round(y[i]/grid_size,0))\n",
    "        weight[i] = grid[index_x][index_y]\n",
    "        # print(centre[0] )\n",
    "    dictionary = {pix: weight[i] for i, pix in enumerate(neighbours)}\n",
    "    result = np.array(list(dictionary.items())).flatten()\n",
    "\n",
    "    return pix_ring, result\n",
    "    # return {pix: weight[i] for i, pix in enumerate(neighbours)}    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb409c-7c39-4405-bff2-3c3f2f18dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=0\n",
    "duration = 100000 # in min (one month)\n",
    "steps = int(duration / scan_time)\n",
    "# steps = 10000\n",
    "length = 50\n",
    "format_string = '\\t'.join(['%d', '%.8e'] * length)\n",
    "centre_pix_format = \"%d\"\n",
    "\n",
    "fmt = [centre_pix_format] + format_string.split('\\t')  # Split format_string by tabs\n",
    "\n",
    "time_periods = np.linspace(start_time, start_time + duration, steps)\n",
    "time_periods_iterator = tqdm(time_periods, desc=\"Processing\", total=len(time_periods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b7a19-81fd-4835-9a45-60b4151a1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(time_periods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813369d9-38a8-4776-b5bd-76009cdfcd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save map.dat occurance, centre_pix, neighbors_weights\n",
    "import numpy as np\n",
    "format_string = '\\t'.join(['%d', '%.8e'] * 50)\n",
    "centre_pix_format = \"%d\"\n",
    "occurance_format = \"%d\"\n",
    "\n",
    "fmt = [occurance_format] + [centre_pix_format] + format_string.split('\\t')  # Split format_string by tabs\n",
    "\n",
    "nside = 16\n",
    "npix = 12*nside**2\n",
    "\n",
    "array_map = np.zeros((npix, 102))\n",
    "\n",
    "array_map[:, 1] = np.arange(npix)\n",
    "array_map[:, 0] = 0\n",
    "\n",
    "array_map[:, 2] = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50babbf2-2f10-4032-801f-76f33ea34068",
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_period in tqdm(time_periods, desc=\"Processing\"):\n",
    "    pixel, weight = process_time_step(time_period)\n",
    "    result = np.pad(weight, (0, 2 * length - len(weight)), mode='constant', constant_values=0)\n",
    "    idx = int(pixel)\n",
    "    array_map[idx,2:] += result \n",
    "\n",
    "np.savetxt(\"check1.dat\",array_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ffe0b-6027-4830-b568-6c81680946bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e342d5-baf3-4f17-89a4-589ab5f76f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, Lock\n",
    "\n",
    "def process_time_step_wrapper(time_period):\n",
    "    \"\"\"Wrapper function to avoid pickling issues with Pool\"\"\"\n",
    "    pixel, weight = process_time_step(time_period)\n",
    "    return pixel, weight\n",
    "\n",
    "def parallel_process(time_periods, num_processes, array_map, length):\n",
    "    \"\"\"\n",
    "    Parallel processing function using Pool for efficient execution\n",
    "\n",
    "    Args:\n",
    "        time_periods: List of time periods to be processed.\n",
    "        num_processes: Number of processes to use for parallel execution.\n",
    "        array_map: The array to be updated.\n",
    "        length: The length to use for padding the weight.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        # Process time steps in parallel and collect results\n",
    "        results = pool.starmap(process_time_step_wrapper, zip(time_periods))\n",
    "\n",
    "        # Create a lock object to prevent race conditions\n",
    "        lock = Lock()\n",
    "\n",
    "        # Update array_map safely using the lock\n",
    "        for pixel, weight in results:\n",
    "            idx = int(pixel)\n",
    "            with lock:\n",
    "                array_map[idx, 0] += 1\n",
    "                array_map[idx, 2:] += np.pad(weight, (0, 2 * length - len(weight)), mode='constant', constant_values=0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample usage (replace with your actual code)\n",
    "    # time_periods = [1, 2, 3, 4, ...]  # Your list of time periods\n",
    "    num_processes = 48\n",
    "    \n",
    "\n",
    "    parallel_process(time_periods, num_processes, array_map, length)\n",
    "\n",
    "    # Rest of your code using the updated array_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d90d8-3d04-4f4b-b941-400612213727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool, Manager\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your process_time_step function here\n",
    "\n",
    "def process_time_step_parallel(time_period):\n",
    "    pixel, weight = process_time_step(time_period)\n",
    "    result = np.pad(weight, (0, 2 * length - len(weight)), mode='constant', constant_values=0)\n",
    "    idx = int(pixel)\n",
    "    return idx, result\n",
    "\n",
    "def update_array_map(result):\n",
    "    global array_map\n",
    "    idx, result = result\n",
    "    with array_map.get_lock():\n",
    "        array_map[idx, 2:] += result\n",
    "        array_map[idx, 0] += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_processes = 48\n",
    "    manager = Manager()\n",
    "    array_map = manager.Array('d', shape=(some_shape, 2 * length))  # Define the shape of your array_map\n",
    "\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        for result in tqdm(pool.imap_unordered(process_time_step_parallel, time_periods), total=len(time_periods), desc=\"Processing\"):\n",
    "            update_array_map(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899baecc-b245-43d1-ae6a-cd7b62ab21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"check1.dat\",array_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251b2de-28ed-45e3-9aa3-972b2e685a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.loadtxt(\"check1.dat\")\n",
    "data2 = np.loadtxt(\"check2.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ccc2d2-9a57-4a7a-922b-c66196064615",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"result.dat\", data2-data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c6f35-58c4-486c-9671-0892a5b7505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_time_step_parallel(time_period):\n",
    "    pixel, weight = process_time_step(time_period)\n",
    "    result = np.pad(weight, (0, 2 * length - len(weight)), mode='constant', constant_values=0)\n",
    "    idx = int(pixel)\n",
    "    return idx, result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool() as pool:\n",
    "        results = list(tqdm(pool.imap(process_time_step_parallel, time_periods), total=len(time_periods), desc=\"Processing\"))\n",
    "\n",
    "    for idx, result in results:\n",
    "        array_map[idx, 2:] += result \n",
    "        array_map[idx, 0] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf4b3f-e2a4-4adf-8f5b-2f91da37c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parallel_execution(chunk, filename):\n",
    "  # Open the file for writing in each process\n",
    "  with open(filename, 'w') as f:\n",
    "    for time_period in tqdm(chunk, desc=\"Processing\"):\n",
    "        pixel, weight = process_time_step(time_period)\n",
    "        result = np.pad(weight, (0, 2 * length - len(weight)), mode='constant', constant_values=0)\n",
    "        result = list(result)\n",
    "        result.insert(0, pixel)\n",
    "\n",
    "        # Format each element in result using corresponding format specifier from fmt\n",
    "        formatted_result = [fmt[i] % result[i] for i in range(len(fmt))]\n",
    "\n",
    "        # Write the formatted result line separated by tabs\n",
    "        f.write('\\t'.join(formatted_result) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Split the time_periods array into chunks\n",
    "chunks = np.array_split(time_periods, 48)\n",
    "\n",
    "# Define filenames for each chunk\n",
    "filenames = [f\"1024_month6_{i+1}.dat\" for i in range(48)]\n",
    "\n",
    "# Using multiprocessing for parallel execution with custom filenames\n",
    "with multiprocessing.Pool(processes=48) as pool:\n",
    "    pool.starmap(parallel_execution, zip(chunks, filenames))\n",
    "\n",
    "print(\"Result processing complete\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
